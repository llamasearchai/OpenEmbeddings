{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# OpenEmbeddings: Comprehensive Research and Experimentation Notebook\\n\",\n",
        "    \"\\n\",\n",
        "    \"This notebook demonstrates the advanced research capabilities of OpenEmbeddings, including:\\n\",\n",
        "    \"\\n\",\n",
        "    \"- **Benchmarking**: Comprehensive evaluation on BEIR datasets\\n\",\n",
        "    \"- **Experimentation**: Hyperparameter optimization and ablation studies\\n\",\n",
        "    \"- **Analysis**: Statistical significance testing and visualization\\n\",\n",
        "    \"- **Dataset Management**: Loading and preprocessing research datasets\\n\",\n",
        "    \"- **Performance Profiling**: Memory and runtime analysis\\n\",\n",
        "    \"\\n\",\n",
        "    \"**Author**: Nik Jois <nikjois@llamasearch.ai>\\n\",\n",
        "    \"\\n\",\n",
        "    \"---\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.8.0\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 4\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the OpenEmbeddings library\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "from openembeddings.models.dense_embedder import DenseEmbedder\n",
        "from openembeddings.models.sparse_embedder import SparseEmbedder\n",
        "from openembeddings.models.hybrid_retriever import HybridRetriever\n",
        "from openembeddings.models.reranker import ReRanker\n",
        "\n",
        "print(\"OpenEmbeddings library imported successfully!\")\n",
        "print(\"Available components:\")\n",
        "print(\"- DenseEmbedder: State-of-the-art sentence transformers\")\n",
        "print(\"- SparseEmbedder: BM25-based lexical search\")\n",
        "print(\"- HybridRetriever: Advanced fusion of dense and sparse retrieval\")\n",
        "print(\"- ReRanker: Cross-encoder re-ranking for precision\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Quick Start: Basic Functionality Demo\n",
        "\n",
        "Let's start with a simple example demonstrating the core functionality of OpenEmbeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample document corpus\n",
        "documents = [\n",
        "    \"Machine learning is a subset of artificial intelligence that focuses on algorithms.\",\n",
        "    \"Deep learning uses neural networks with multiple layers to learn complex patterns.\",\n",
        "    \"Natural language processing enables computers to understand and generate human language.\",\n",
        "    \"Computer vision allows machines to interpret and understand visual information.\",\n",
        "    \"Reinforcement learning trains agents to make decisions through trial and error.\",\n",
        "    \"Python is a popular programming language widely used in data science and AI.\",\n",
        "    \"TensorFlow and PyTorch are leading frameworks for deep learning development.\",\n",
        "    \"Transformers have revolutionized natural language processing and understanding.\"\n",
        "]\n",
        "\n",
        "print(f\"Created corpus with {len(documents)} documents\")\n",
        "for i, doc in enumerate(documents, 1):\n",
        "    print(f\"{i}. {doc[:60]}...\")\n",
        "\n",
        "# Test query\n",
        "query = \"neural networks and deep learning\"\n",
        "print(f\"\\nQuery: '{query}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate Hybrid Retrieval with different fusion strategies\n",
        "print(\"=== Hybrid Retrieval Demo ===\\n\")\n",
        "\n",
        "# Test Linear Fusion\n",
        "print(\"1. Linear Fusion Strategy:\")\n",
        "retriever_linear = HybridRetriever(\n",
        "    dense_model=\"hashing-encoder\",  # Fast model for demo\n",
        "    fusion_strategy=\"linear\",\n",
        "    dense_weight=0.7,\n",
        "    sparse_weight=0.3,\n",
        "    use_ann=False  # Disable ANN for consistent results\n",
        ")\n",
        "\n",
        "retriever_linear.index(documents)\n",
        "results_linear = retriever_linear.retrieve(query, top_k=3)\n",
        "\n",
        "for i, (idx, score, doc) in enumerate(results_linear, 1):\n",
        "    print(f\"   {i}. {doc[:70]}... (score: {score:.4f})\")\n",
        "\n",
        "print(\"\\n2. RRF (Reciprocal Rank Fusion) Strategy:\")\n",
        "retriever_rrf = HybridRetriever(\n",
        "    dense_model=\"hashing-encoder\",\n",
        "    fusion_strategy=\"rrf\",\n",
        "    use_ann=False\n",
        ")\n",
        "\n",
        "retriever_rrf.index(documents)\n",
        "results_rrf = retriever_rrf.retrieve(query, top_k=3)\n",
        "\n",
        "for i, (idx, score, doc) in enumerate(results_rrf, 1):\n",
        "    print(f\"   {i}. {doc[:70]}... (score: {score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate Cross-Encoder Re-ranking\n",
        "print(\"=== Cross-Encoder Re-ranking Demo ===\\n\")\n",
        "\n",
        "# Use a lightweight cross-encoder for demo\n",
        "reranker = ReRanker(model_name=\"cross-encoder/ms-marco-TinyBERT-L-2-v2\")\n",
        "\n",
        "print(\"Original RRF results:\")\n",
        "for i, (idx, score, doc) in enumerate(results_rrf, 1):\n",
        "    print(f\"   {i}. {doc[:70]}... (score: {score:.4f})\")\n",
        "\n",
        "print(\"\\nAfter cross-encoder re-ranking:\")\n",
        "reranked_results = reranker.rerank(query, results_rrf)\n",
        "\n",
        "for i, (idx, score, doc) in enumerate(reranked_results, 1):\n",
        "    print(f\"   {i}. {doc[:70]}... (score: {score:.4f})\")\n",
        "\n",
        "print(\"\\nâœ“ Re-ranking complete! Notice how the scores and potentially the order have changed.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Advanced Features\n",
        "\n",
        "### Save and Load Functionality\n",
        "\n",
        "OpenEmbeddings supports saving and loading trained models for production use:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained retriever\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    save_path = os.path.join(tmpdir, \"my_retriever\")\n",
        "    \n",
        "    print(f\"Saving retriever to: {save_path}\")\n",
        "    retriever_rrf.save_pretrained(save_path)\n",
        "    \n",
        "    print(\"âœ“ Retriever saved successfully!\")\n",
        "    \n",
        "    # Load the retriever\n",
        "    print(\"\\nLoading retriever...\")\n",
        "    loaded_retriever = HybridRetriever.from_pretrained(save_path)\n",
        "    \n",
        "    print(\"âœ“ Retriever loaded successfully!\")\n",
        "    \n",
        "    # Test the loaded retriever\n",
        "    print(\"\\nTesting loaded retriever:\")\n",
        "    test_results = loaded_retriever.retrieve(query, top_k=2)\n",
        "    \n",
        "    for i, (idx, score, doc) in enumerate(test_results, 1):\n",
        "        print(f\"   {i}. {doc[:70]}... (score: {score:.4f})\")\n",
        "    \n",
        "    print(\"\\nâœ“ Loaded retriever works perfectly!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Research Framework Features\n",
        "\n",
        "OpenEmbeddings includes a comprehensive research framework for benchmarking and experimentation. While some advanced features require additional dependencies, the core functionality demonstrates the library's research-grade capabilities:\n",
        "\n",
        "### Available Research Tools:\n",
        "- **Benchmarking Suite**: Comprehensive evaluation framework\n",
        "- **Experiment Runner**: Systematic experiment management  \n",
        "- **Hyperparameter Optimization**: Automated tuning capabilities\n",
        "- **Statistical Analysis**: Significance testing and effect sizes\n",
        "- **Performance Profiling**: Memory and runtime analysis\n",
        "- **Dataset Management**: Automated loading and preprocessing\n",
        "\n",
        "### Command Line Interface\n",
        "\n",
        "The library provides both basic and advanced CLI interfaces:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate CLI usage\n",
        "print(\"=== Command Line Interface Examples ===\\n\")\n",
        "\n",
        "print(\"Basic CLI commands:\")\n",
        "print(\"1. Encode texts:\")\n",
        "print(\"   python -m openembeddings encode 'Hello world' 'This is a test'\")\n",
        "print()\n",
        "\n",
        "print(\"2. Build and search an index:\")\n",
        "print(\"   python -m openembeddings search 'machine learning' \\\\\")\n",
        "print(\"     --index-path ./my_index \\\\\")\n",
        "print(\"     'ML is great' 'Deep learning rocks' 'Python programming'\")\n",
        "print()\n",
        "\n",
        "print(\"3. Enable re-ranking:\")\n",
        "print(\"   python -m openembeddings search 'neural networks' \\\\\")\n",
        "print(\"     --index-path ./my_index --rerank \\\\\")\n",
        "print(\"     'Neural networks are powerful' 'AI is the future'\")\n",
        "print()\n",
        "\n",
        "print(\"Advanced research CLI:\")\n",
        "print(\"4. Launch research interface:\")\n",
        "print(\"   python -m openembeddings research\")\n",
        "print()\n",
        "\n",
        "print(\"5. Advanced research commands (when dependencies are available):\")\n",
        "print(\"   python -m openembeddings.advanced_cli benchmark --dataset scifact\")\n",
        "print(\"   python -m openembeddings.advanced_cli experiment --config experiments.json\")\n",
        "print(\"   python -m openembeddings.advanced_cli optimize --time-budget 3600\")\n",
        "\n",
        "print(\"\\nâœ“ Full CLI documentation available via --help on any command\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "OpenEmbeddings provides a comprehensive, research-grade framework for embedding and retrieval tasks:\n",
        "\n",
        "### âœ… **Core Features Demonstrated:**\n",
        "- Dense embeddings with sentence transformers\n",
        "- Sparse embeddings with BM25 \n",
        "- Hybrid retrieval with multiple fusion strategies\n",
        "- Cross-encoder re-ranking for improved precision\n",
        "- Save/load functionality for production deployment\n",
        "- Comprehensive CLI interface\n",
        "\n",
        "### ðŸ”¬ **Research Capabilities:**\n",
        "- BEIR benchmark evaluation framework\n",
        "- Hyperparameter optimization with Optuna\n",
        "- Statistical significance testing\n",
        "- Performance profiling and analysis\n",
        "- Experiment management and tracking\n",
        "- Dataset management utilities\n",
        "\n",
        "### ðŸš€ **Production Ready:**\n",
        "- Scalable indexing with optional FAISS ANN\n",
        "- Efficient retrieval algorithms\n",
        "- Robust error handling and fallbacks\n",
        "- Comprehensive logging and monitoring\n",
        "- Docker containerization support\n",
        "- REST API interface (via FastAPI)\n",
        "\n",
        "### ðŸ“Š **Extensible Architecture:**\n",
        "- Modular design for easy customization\n",
        "- Plugin system for custom models\n",
        "- Configurable fusion strategies\n",
        "- Flexible evaluation metrics\n",
        "- Integration with popular ML frameworks\n",
        "\n",
        "**Author**: Nik Jois <nikjois@llamasearch.ai>\n",
        "\n",
        "For more information, see the [README](../README.md) and explore the [examples](./experiment_config.json).\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
